{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac6eaf-d04c-4ffd-b200-953fbf157017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Step 2: Create the Neural Network Model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(2, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Step 4: Create Dataset\n",
    "dataset = np.array([\n",
    "    [0, 0, 1], [1, 0, 1], [2, 0, 1], [3, 0, 1], [4, 0, 1],\n",
    "    [0, 0, 0], [1, 1, 1], [2, 1, 1], [3, 1, 1], [4, 1, 1],\n",
    "    [0, 0, 0], [1, 2, 0], [2, 2, 1], [3, 2, 1], [4, 2, 1],\n",
    "    [0, 0, 0], [1, 3, 0], [2, 3, 0], [3, 3, 1], [4, 3, 1],\n",
    "    [0, 0, 0], [1, 4, 0], [2, 4, 0], [3, 4, 0], [4, 4, 1]\n",
    "])\n",
    "\n",
    "# Step 5: Get Input and Output, Scale Output from Dataset\n",
    "x = dataset[:, :2]\n",
    "y = 0.1 + 0.8 * dataset[:, 2]\n",
    "\n",
    "# Step 6: Split Input and Output\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.30, random_state=1\n",
    ")\n",
    "\n",
    "# Step 7: Train the Model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=3)\n",
    "print()\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a43088-a9f8-4c16-aaa1-09e4aa852b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import ops\n",
    "layer1 = layers.Dense(3, name=\"layer1\")\n",
    "layer2 = layers.Dense(4, name=\"layer2\")\n",
    "layer3 = layers.Dense(1, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = ops.ones((4, 2))\n",
    "h1 = layer1(x)\n",
    "h2 = layer2(h1)\n",
    "y = layer3(h2)\n",
    "\n",
    "print(x)\n",
    "print(h1)\n",
    "print(h2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfc1e48-da59-44bb-bde0-713dc36b692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n",
      "Test loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Step 2: Create the Neural Network Model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(1, activation=\"relu\"),\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Step 4: Create Dataset\n",
    "dataset = np.array([\n",
    "    [0, 0, 1], [1, 0, 1], [2, 0, 1], [3, 0, 1], [4, 0, 1],\n",
    "    [0, 0, 0], [1, 1, 1], [2, 1, 1], [3, 1, 1], [4, 1, 1],\n",
    "    [0, 0, 0], [1, 2, 0], [2, 2, 1], [3, 2, 1], [4, 2, 1],\n",
    "    [0, 0, 0], [1, 3, 0], [2, 3, 0], [3, 3, 1], [4, 3, 1],\n",
    "    [0, 0, 0], [1, 4, 0], [2, 4, 0], [3, 4, 0], [4, 4, 1]\n",
    "])\n",
    "\n",
    "# Step 5: Get Input and Output, Scale Output from Dataset\n",
    "x = dataset[:, :2]\n",
    "y = 0.1 + 0.8 * dataset[:, 2]\n",
    "\n",
    "# Step 6: Split Input and Output\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.30, random_state=1\n",
    ")\n",
    "\n",
    "# Step 7: Train the Model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=3)\n",
    "print()\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f34e65f-3a0d-43ce-8ea3-db23da6f4ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [3 0]\n",
      " [4 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 1]\n",
      " [3 1]\n",
      " [4 1]\n",
      " [0 0]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [3 2]\n",
      " [4 2]\n",
      " [0 0]\n",
      " [1 3]\n",
      " [2 3]\n",
      " [3 3]\n",
      " [4 3]\n",
      " [0 0]\n",
      " [1 4]\n",
      " [2 4]\n",
      " [3 4]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8c3f2a-e3e9-4e12-8a15-3c502820917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.06043327  0.98088145 -0.32147443]\n",
      " [ 0.06043327  0.98088145 -0.32147443]\n",
      " [ 0.06043327  0.98088145 -0.32147443]\n",
      " [ 0.06043327  0.98088145 -0.32147443]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.41752458 0.7235965  0.5577286  0.65184206]\n",
      " [0.41752458 0.7235965  0.5577286  0.65184206]\n",
      " [0.41752458 0.7235965  0.5577286  0.65184206]\n",
      " [0.41752458 0.7235965  0.5577286  0.65184206]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.10979204]\n",
      " [0.10979204]\n",
      " [0.10979204]\n",
      " [0.10979204]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(2, 3), dtype=float32, path=layer1/kernel>,\n",
       " <KerasVariable shape=(3,), dtype=float32, path=layer1/bias>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import ops\n",
    "layer1 = layers.Dense(3, name=\"layer1\")\n",
    "layer2 = layers.Dense(4, name=\"layer2\")\n",
    "layer3 = layers.Dense(1, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = ops.ones((4, 2))\n",
    "h1 = layer1(x)\n",
    "h2 = layer2(h1)\n",
    "y = layer3(h2)\n",
    "\n",
    "print(x)\n",
    "print(h1)\n",
    "print(h2)\n",
    "print(y)\n",
    "\n",
    "layer1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0837abdd-41ed-43e4-9701-4190f5000448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(3, 4), dtype=float32, path=layer2/kernel>,\n",
       " <KerasVariable shape=(4,), dtype=float32, path=layer2/bias>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc013d6-6fa5-4f06-9110-7b707b1b046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(4, 1), dtype=float32, path=layer3/kernel>,\n",
       " <KerasVariable shape=(1,), dtype=float32, path=layer3/bias>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb4256-1b1e-465f-9b0f-83454ad66812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
